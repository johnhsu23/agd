<div class="main__header">
  <div class="l-constrain in-page-nav-wrapper"></div>
</div>
<div class="main__inner">
  <div class="section" id="about">
    <div class="section__inner">
      <div class="section__title">About the NAEP Arts Assessment</div>
      <div class="section__commentary">
        <p>The National Assessment of Educational Progress (NAEP) arts assessment measured students’ knowledge and skills in the arts disciplines of music and visual arts. Students were evaluated in two arts processes—responding and creating. In music, responding questions asked students to analyze, interpret, or critique a piece of music that they listened to or to describe the social, historical, or cultural context of a piece of music. Creating questions asked students to use musical notation to apply their musical ideas after evaluating written or recorded pieces of music. In visual arts, responding questions asked students to analyze, describe, or judge works of art and design to show understanding of form, aesthetics, and cultural or historical context. Creating questions asked students to use form, media, or techniques to create original works of art and design to communicate an idea.</p>
        <p>In 2016, performance results at grade 8 were reported for the nation overall and for selected student demographic groups, such as race/ethnicity, gender, and the highest level of parental education.</p>
      </div>
    </div>
  </div>

  <div class="section" id="framework">
    <div class="section__inner">
      <div class="section__title">The NAEP Arts Framework</div>
      <div class="section__commentary">
        <p>The <a target="_blank" href="http://nces.ed.gov/nationsreportcard/about/nagb/">National Assessment Governing Board (NAGB) </a>oversees the development of NAEP frameworks that describe the specific knowledge and skills to be assessed in each subject and how the assessment questions should be designed and scored.</p>
        <p>The NAEP arts assessment framework is rooted in the belief that the arts are essential to every child’s complete development. The arts are as basic as literacy and numeracy in U.S. education and are an important vehicle for learning the skills valued by education reformers and the business community, including problem-solving, higher order thinking, flexibility, persistence, and cooperation. In addition, the arts have a unique capacity to integrate the intellect, emotions, and physical skills to construct meaning. In order for students to place the arts in broader contexts and to fully appreciate their significance, they need to have the ability to use artistic processes—such as creating and responding—to draw upon their knowledge and understanding of the arts in order to construct meaning.</p>
        <p>The arts assessment was developed and reviewed by a committee of arts experts to capture the goals of the <a target="_blank" href="https://www.nagb.org/publications/frameworks/arts/2016-arts-framework.html">arts framework</a>. NAGB oversaw a comprehensive national process reflecting the input of arts educators, artists, assessment specialists, policymakers, representatives from the business community, and members of the public. The National Standards for Arts Education also served as an important reference in the development of the NAEP arts framework.</p>
        <p>The arts framework specifies that students’ arts knowledge and skills be measured in four arts disciplines: music, visual arts, dance, and theatre. Additionally, three arts processes—responding, creating, and performing—are central to students’ experiences in these disciplines. The responding process refers to observing, describing, analyzing, and evaluating works of art, while the creating process refers to expressing ideas and feelings in the form of an original work of art. Due to the small percentage of schools with dance and theatre programs, only the responding and creating processes in music and visual arts were assessed in 2016 and in 2008, the previous assessment year.</p>
      </div>
    </div>
  </div>

  <div class="section" id="design">
    <div class="section__inner">
      <div class="section__title">Assessment Design and Scoring</div>
      <div class="section__commentary">
        <p>Because of the breadth of content covered in the NAEP arts assessment, each student was assessed in only one arts discipline, either music or visual arts. Music and visual arts were not administered in the same classrooms.  Students in the same classroom were administered the same test booklet in music or visual arts. The responding process in both music and visual arts was assessed with multiple-choice questions and constructed-response questions that asked students to write an answer of a few words or sentences. The creating process in visual arts was assessed by constructed response questions that required students to both generate written answers and to create their own original works of visual art. For the creating task portion of the visual arts assessment, students were provided with a variety of materials such as drawing paper, construction paper, watercolor markers, and oil pastels. Read more about the <a target="_blank" href="https://nces.ed.gov/nationsreportcard/arts/moreabout.aspx#students">types of questions</a> included on the arts assessment.</p>
		<p>In the music portion of the assessment, students were paced through the cognitive sections via compact disc (CD). Some complex tasks in visual arts also used paced CDs. Therefore, all students in a given session were administered the same test booklet. The timing of the music booklets ranged from 58-63 minutes and the timing of visual arts booklets ranged from 75-104 minutes.</p>
        <p>One of the challenges of the arts assessment was scoring students’ work, due to the nature of the question types. Unlike most other NAEP assessments, visual arts included tasks which required students to create their responses (e.g., drawing), in addition to questions which required traditional response types such as writing. Specific scoring guides were developed for the responding questions in music and the responding and creating questions in visual arts. Scorers were then trained to apply these criteria appropriately when evaluating students’ responses that demonstrated a wide range of skill levels in music and visual arts. The scoring guides for the sample questions presented in this report, and other released questions from the assessment, are available in the <a target="_blank" href="http://nces.ed.gov/nationsreportcard/nqt/">NAEP Questions Tool (NQT)</a>.</p>
      </div>
    </div>
  </div>

  <div class="section" id="samples">
    <div class="section__inner">
      <div class="section__title">NAEP Samples</div>
      <div class="section__commentary">
        <p>The schools and students participating in NAEP assessments are selected to be representative of all schools and students nationally. The results from the 2016 arts assessment at grade 8 were based on a representative sample of 8,800 eighth-graders from 280 schools. Approximately one-half of the eighth-grade students were assessed in music (4,300 students) and the other half were assessed in visual arts (4,400 students). The national sample of schools and students is drawn from across the country. The results from the assessed students are combined to provide accurate estimates of the overall performance of students in the nation. Unlike NAEP assessments in other subjects, such as reading, mathematics, and science, the arts assessment sample was not designed to report results for individual states or large urban districts. Download the <a href="ets-arts-2016.dev.forumone.com/#about#footer">summary data tables</a> via the link at the bottom of the page to see the national sample sizes for the 2016 arts assessment.</p>
        <p>Each school that participated in the assessment, and each student assessed, represents only a portion of the larger population of interest. The results are weighted to account for the disproportionate representation of some groups in the selected sample, including the oversampling of schools with high concentrations of students from certain racial/ethnic groups and the lower sampling rates of students who attend small schools. Read more about NAEP <a target="_blank" href="http://nces.ed.gov/nationsreportcard/tdw/sample_design/">sampling</a> and <a target="_blank" href="http://nces.ed.gov/nationsreportcard/tdw/weighting/">weighting</a> in the NAEP Technical Documentation.</p>
      </div>
    </div>
  </div>

  <div class="section" id="inclusion">
    <div class="section__inner">
      <div class="section__title">NAEP Inclusion</div>
      <div class="section__commentary">
        <p>It is important for NAEP to assess as many students selected to participate as possible. Assessing representative samples of students, including <a href="" class="iframe cboxElement" data-glossary="sd">students with disabilities (SD)</a> and <a href="" class="iframe cboxElement" data-glossary="ell">English language learners (ELL)</a>, helps to ensure that NAEP results accurately reflect the educational performance of all students in the target population, and can continue to serve as a meaningful measure of U.S. students’ academic achievement over time.</p>
        <p>To ensure that all selected students from the population can be assessed, many of the same accommodations that SD and ELL students use on other tests are provided for those students participating in NAEP. Read more about <a target="_blank" href="https://nces.ed.gov/nationsreportcard/about/accom_table.aspx">accommodations available in NAEP</a>. Even with the availability of accommodations, some students may still be excluded. Download the <a href="ets-arts-2016.dev.forumone.com/#about#footer">summary data tables</a> via the link at the bottom of the page to see the percentages of SD and/or ELL students identified, excluded, and assessed in 2016 in arts.</p>
        <p>The National Assessment Governing Board, which sets policy for NAEP, has been exploring ways to ensure that NAEP continues to appropriately include as many students as possible and to do so in a consistent manner for all jurisdictions and districts assessed and for which results are reported. In March 2010, the Governing Board adopted a new policy outlining specific inclusion goals for NAEP samples. The goal is to include 95 percent of all students selected for the NAEP samples, and 85 percent of those in the NAEP sample who are identified as SD or ELL. Read more about the <a target="_blank" href="http://nces.ed.gov/nationsreportcard/about/inclusion.aspx">inclusion policy</a> and how the percentages of students are calculated.</p>
      </div>
    </div>
  </div>

  <div class="section" id="participation">
    <div class="section__inner">
      <div class="section__title">School and Student Participation</div>
      <div class="section__commentary">
        <p>To ensure unbiased samples, NAEP requires that participation rates for original school samples be 70 percent or higher to report national results separately for public and private schools. In 2016, the school participation rates for private and Catholic schools overall met the 70 percent criteria for reporting in music and visual arts at grade 8 and the results are therefore included in this report. In instances where participation rates meet the 70 percent criteria but fall below 85 percent, a nonresponse <a href="" class="iframe cboxElement" data-glossary="bias">bias</a> analysis is conducted to determine whether the responding school sample is not representative of the population, thereby introducing the potential for nonresponse bias.  </p>
        <p>Before substituting replacement schools for originally sampled schools that declined to participate, the weighted national school participation rates for the music and visual arts portions of the 2016 arts assessment at grade 8 were 93 percent (95 percent for public schools, 76 percent for private schools, and 100 percent for Catholic schools).</p>
        <p>Weighted student participation rates at grade 8 were 93 percent for the music portion of the assessment (93 percent for public school students, 91 percent for private school students, and 93 percent for Catholic school students); for the visual arts portion, weighted student participation rates were 94 percent at grade 8 (94 percent for public school students, 93 percent for private school students, and 95 percent for Catholic school students.</p>
        <p>Nonresponse bias analyses were conducted for the private school sample (which included Catholic schools) at grade 8 in 2016. The results showed that school substitution and nonresponse adjustments were effective in reducing the potential for nonresponse bias in the arts assessment.</p>
        <p>Download the <a href="ets-arts-2016.dev.forumone.com/#about#footer">summary data tables</a> via the link at the bottom of the page to see the participation rates in arts for the nation.</p>
      </div>
    </div>
  </div>

  <div class="section" id="reporting">
    <div class="section__inner">
      <div class="section__title">Reporting NAEP Results</div>
      <div class="section__commentary">
        <p>NAEP music and visual arts results responding scores are reported separately as average scores on a 0–300 scale, and the music and visual arts scales are based on responding questions only. An overall “arts” scale score is not reported nor are achievement level results. The visual arts results also include an average creating task score reported as the average percentage maximum possible score from 0 to 100. The creating task score for each creating question (task) is the sum of the percentage of students receiving full credit and a fraction of the percentage of students receiving partial credit. The individual scores are then averaged together to report an average creating task score for the entire set of the visual arts creating questions.</p>
        <p>The 2016 arts assessment included only one music creating questions; therefore, an average creating task score was not reported for the music portion of the arts assessment. Since music and visual arts are two distinct disciplines, results are reported separately for each area and cannot be compared. Because NAEP scores are developed independently for each subject, results cannot be compared across subjects. Read more about the NAEP <a target="_blank" href="http://nces.ed.gov/nationsreportcard/tdw/analysis/describing.aspx">scaling</a> process. Learn how the <a target="_blank" href="http://nces.ed.gov/nationsreportcard/arts/interpret_results.aspx">average creating task score</a> in NAEP visual arts is calculated.</p>
        <p>Results are reported for students overall and for selected demographic groups such as race/ethnicity, gender, and highest level of parental education. Read more about how student groups are defined and <a target="_blank" href="http://nces.ed.gov/nationsreportcard/arts/interpret_results.aspx">how to interpret NAEP results</a> from the arts assessment.</p>
        <p>NAEP reports results using widely accepted statistical standards; findings are reported based on a statistical significance level set at .05 with appropriate adjustments for multiple comparisons. Only those differences that are found to be statistically significant are referred to as “higher” or “lower.” </p>
        <p>Comparisons over time of scores and percentages or between groups are based on statistical tests that consider both the size of the difference and the standard errors of the two statistics being compared. Standard errors are margins of error, and estimates based on smaller groups are likely to have larger margins of error. For example, a 2-point change in the average score for one student demographic group may be statistically significant, while a 2-point score change for another student group is not, due to the size of the standard error. The size of the standard errors may also be influenced by other factors, such as the degree to which the assessed students are representative of the entire population. Standard errors for the estimates presented in this report are available in the <a target="_blank" href="http://nces.ed.gov/nationsreportcard/naepdata/">NAEP Data Explorer (NDE)</a>.  </p>
        <p>Average scores and percentages of students are presented as whole numbers in the report; however, the statistical comparison tests are based on unrounded numbers. In some cases, the scores or the percentages have the same whole number values, but they are statistically different from each other. The “Customize data tables” link at the bottom of the page provides data tables from the NAEP Data Explorer (NDE). The tables offer detailed information on more precise values for the scores and percentages and explain how the two comparison estimates differ from each other.</p>
        <p>A scale score that is significantly higher or lower in comparison to an earlier assessment year is reliable evidence that student performance has changed. NAEP is not, however, designed to identify the causes of change in student performance. Although comparisons are made in students’ performance based on demographic characteristics and educational experiences, the comparisons cannot be used to establish a cause-and-effect relationship between the characteristic or experience and achievement. Many factors may influence student achievement, including educational policies and practices, available resources, and the demographic characteristics of the student body. Such factors may change over time and vary among student groups.</p>
      </div>
    </div>
  </div>

  <div class="section" id="compare">
    <div class="section__inner">
      <div class="section__title">Comparing Results Between the 2016, 2008, and 1997 Arts Assessments</div>
      <div class="section__commentary">
        <p>Although the NAEP arts assessment was administered in 1997, the responding score results from 1997 cannot be directly compared to either the 2008 or 2016 responding score results in music and visual arts due to changes in training and scoring procedures that were adapted for use across all NAEP assessments since 1997. In addition, due to the degradation of student artwork used as training samples for scoring visual arts questions in 1997 as well as changes in the availability of certain arts supplies and tools since 1997, new scoring samples were developed for assessing students’ responses to creating questions in 2008 and 2016. Trend comparisons for the visual arts creating task score cannot be made because scoring procedures for some of the 2008 visual arts creating questions could not be replicated in 2016. Read more about <a target="_blank" href="https://nces.ed.gov/nationsreportcard/arts/interpret_results.aspx">trend comparisons</a> in the NAEP arts assessment.  </p>
        <p>However, since the scoring method for multiple-choice questions was the same in 1997, 2008, and 2016, direct comparisons can be made between the three assessment years on results for these questions in both music and visual arts. Since multiple-choice questions comprised a portion of the assessment and only assessed certain types of topics in the responding process of music and visual arts, the changes in students’ performance across the three assessment years on these questions did not represent the performance changes for the constructed-response questions or the entire assessment.  See <a target="_blank" href="http://nces.ed.gov/nationsreportcard/arts/interpret_results.aspx">trend results</a> for multiple-choice questions from the 1997, 2008, and 2016 arts assessments.  </p>
      </div>
    </div>
  </div>

  <div class="section" id="contacts">
    <div class="section__inner">
      <div class="section__title">Contacts</div>
      <div class="section__commentary">
        <p>The <a target="_blank" href="http://nces.ed.gov/nationsreportcard/">National Assessment of Educational Progress (NAEP)</a> is a congressionally authorized project sponsored by the <a target="_blank" href="http://www.ed.gov/">U.S. Department of Education</a>. The <a target="_blank" href="https://nces.ed.gov/">National Center for Education Statistics</a>, within the <a target="_blank" href="http://ies.ed.gov/">Institute of Education Sciences</a>, administers NAEP. The Commissioner of Education Statistics is responsible by law for carrying out the NAEP project. The <a target="_blank" href="https://www.nagb.org/">National Assessment Governing Board</a> oversees and sets policy for NAEP.</p>
        <p>For questions related to the NAEP administration or this report’s results, contact <a href="mailto:Grady.Wilburn@ed.gov">Grady Wilburn</a>.</p>
        <p>For policy- or framework-related questions, contact the <a target="_blank" href="https://www.nagb.org/">National Assessment Governing Board</a> or call 202-357-6938.</p>
      </div>
    </div>
  </div>
</div>

<div class="main__footer">
	<div class="inner l-constrain"></div>
</div>
